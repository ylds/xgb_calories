# ğŸ” Feature Engineering & Model Insights

This project demonstrates a structured approach to improving calorie expenditure prediction using Gradient Boosting (XGBoost). The workflow includes:

* ğŸ‹ï¸â€â™‚ï¸ **Domain-informed features** such as BMI calculation

* ğŸ”— **Pairwise interaction terms** to capture nonlinear relationships

* âš–ï¸ **Model complexity control** to avoid overfitting via selective feature crosses

* ğŸ“Š **Incremental model evaluation** across versions (v1â€“v5), tracking RMSE:

  * ğŸš€ **v1:** Baseline model with raw features â€“ Final CV RMSE: 0.101
  * ğŸ”„ **v3:** Added multiplication and division terms (division removed later)
  * ğŸ“ˆ **v4:** Added BMI â€“ improved explainability & consistent performance
  * ğŸ¯ **v5:** Combined BMI and cross features â€“ Final RMSE \~0.0600

* â±ï¸ **Model tuning** with early stopping, regularization (`gamma`, `max_delta_step`), and 8-fold cross-validation

* âš¡ **Efficient training time** (\~59 seconds/fold on GPU) and stable convergence around iteration 400

---

## ğŸ† Final Result

The final model achieved a cross-validated RMSE of approximately **0.0600**, indicating strong predictive accuracy. Feature engineering significantly enhanced the modelâ€™s ability to learn meaningful interactions without overfitting.

## EDA

Distribution of the calories
<img width="730" height="566" alt="image" src="https://github.com/user-attachments/assets/6041a760-abb7-4d4e-9eb1-da74fd479e9e" />



